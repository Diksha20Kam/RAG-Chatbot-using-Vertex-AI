import streamlit as st
from rag_pipeline import (
    load_and_split_pdf,
    build_vector_store,
    retrieve_context,
    ask_gemini
)

st.set_page_config(page_title="ğŸ§  RAG Chatbot with Vertex AI")

st.title("ğŸ“„ RAG Chatbot using Vertex AI + LangChain")
st.markdown("Ask questions based on the PDF.")

pdf_path = "/Users/admin/Downloads/Mastering RAG.pdf"

if "faiss_store" not in st.session_state:
    with st.spinner("ğŸ” Reading and embedding PDF..."):
        try:
            docs = load_and_split_pdf(pdf_path)
            st.session_state.faiss_store = build_vector_store(docs)
            st.success("âœ… PDF processed successfully!")
        except Exception as e:
            st.error(f"Error loading PDF: {e}")

query = st.text_input("Ask your question:")

if query and "faiss_store" in st.session_state:
    with st.spinner("ğŸ’¬ Generating answer..."):
        context_docs = retrieve_context(query, st.session_state.faiss_store)
        combined_context = "\n\n".join([doc.page_content for doc in context_docs])
        answer = ask_gemini(combined_context, query)
        st.markdown("### ğŸ¤– Answer:")
        st.write(answer)